{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe486f2e",
   "metadata": {},
   "source": [
    "# Fall‑risk prediction on the gait analysis data\n",
    "\n",
    "This notebook demonstrates how to load the combined gait dataset, preprocess it, handle class imbalance, train multiple models (Logistic Regression, Random Forest and XGBoost), and evaluate them on a hold‑out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1044351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10ded99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('combined_output.csv')\n",
    "# Map labels to binary\n",
    "y = df['Faller'].map({'F': 1, 'NF': 0})\n",
    "# Drop ID and label, convert to numeric and fill missing values\n",
    "X = df.drop(columns=['ID', 'Faller']).apply(pd.to_numeric, errors='coerce')\n",
    "X = X.fillna(X.median())\n",
    "print('Dataset shape:', X.shape)\n",
    "print('Class distribution:', y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe13383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train/test with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Oversample the minority class in the training set\n",
    "train_df = X_train.copy()\n",
    "train_df['label'] = y_train\n",
    "majority = train_df[train_df['label'] == 0]\n",
    "minority = train_df[train_df['label'] == 1]\n",
    "minority_over = resample(minority, replace=True, n_samples=len(majority), random_state=42)\n",
    "train_bal = pd.concat([majority, minority_over])\n",
    "X_train_bal = train_bal.drop(columns=['label'])\n",
    "y_train_bal = train_bal['label']\n",
    "\n",
    "print('Balanced training set shape:', X_train_bal.shape)\n",
    "print('Balanced class distribution:', y_train_bal.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f029f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_bal)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "log_reg.fit(X_train_scaled, y_train_bal)\n",
    "\n",
    "y_pred_lr = log_reg.predict(X_test_scaled)\n",
    "y_prob_lr = log_reg.predict_proba(X_test_scaled)[:,1]\n",
    "\n",
    "acc_lr = accuracy_score(y_test, y_pred_lr)\n",
    "prec_lr = precision_score(y_test, y_pred_lr, zero_division=0)\n",
    "rec_lr = recall_score(y_test, y_pred_lr)\n",
    "f1_lr = f1_score(y_test, y_pred_lr)\n",
    "auc_lr = roc_auc_score(y_test, y_prob_lr)\n",
    "\n",
    "print('Logistic Regression:')\n",
    "print('Accuracy:', acc_lr)\n",
    "print('Precision:', prec_lr)\n",
    "print('Recall:', rec_lr)\n",
    "print('F1:', f1_lr)\n",
    "print('ROC AUC:', auc_lr)\n",
    "\n",
    "# Confusion matrix\n",
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted NF','Predicted F'], yticklabels=['True NF','True F'])\n",
    "plt.title('Logistic Regression Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8c53cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train_bal, y_train_bal)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_prob_rf = rf.predict_proba(X_test)[:,1]\n",
    "\n",
    "acc_rf = accuracy_score(y_test, y_pred_rf)\n",
    "prec_rf = precision_score(y_test, y_pred_rf, zero_division=0)\n",
    "rec_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "auc_rf = roc_auc_score(y_test, y_prob_rf)\n",
    "\n",
    "print('Random Forest:')\n",
    "print('Accuracy:', acc_rf)\n",
    "print('Precision:', prec_rf)\n",
    "print('Recall:', rec_rf)\n",
    "print('F1:', f1_rf)\n",
    "print('ROC AUC:', auc_rf)\n",
    "\n",
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted NF','Predicted F'], yticklabels=['True NF','True F'])\n",
    "plt.title('Random Forest Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546b96a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "xgb_model = XGBClassifier(random_state=42, eval_metric='logloss', n_estimators=200, max_depth=4, learning_rate=0.1, subsample=0.8, colsample_bytree=0.8)\n",
    "xgb_model.fit(X_train_bal, y_train_bal)\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "y_prob_xgb = xgb_model.predict_proba(X_test)[:,1]\n",
    "\n",
    "acc_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "prec_xgb = precision_score(y_test, y_pred_xgb, zero_division=0)\n",
    "rec_xgb = recall_score(y_test, y_pred_xgb)\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb)\n",
    "auc_xgb = roc_auc_score(y_test, y_prob_xgb)\n",
    "\n",
    "print('XGBoost:')\n",
    "print('Accuracy:', acc_xgb)\n",
    "print('Precision:', prec_xgb)\n",
    "print('Recall:', rec_xgb)\n",
    "print('F1:', f1_xgb)\n",
    "print('ROC AUC:', auc_xgb)\n",
    "\n",
    "cm_xgb = confusion_matrix(y_test, y_pred_xgb)\n",
    "sns.heatmap(cm_xgb, annot=True, fmt='d', cmap='Blues', xticklabels=['Predicted NF','Predicted F'], yticklabels=['True NF','True F'])\n",
    "plt.title('XGBoost Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e2bb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize results in a DataFrame\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'XGBoost'],\n",
    "    'Accuracy': [acc_lr, acc_rf, acc_xgb],\n",
    "    'Precision': [prec_lr, prec_rf, prec_xgb],\n",
    "    'Recall': [rec_lr, rec_rf, rec_xgb],\n",
    "    'F1': [f1_lr, f1_rf, f1_xgb],\n",
    "    'ROC AUC': [auc_lr, auc_rf, auc_xgb]\n",
    "})\n",
    "results"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
